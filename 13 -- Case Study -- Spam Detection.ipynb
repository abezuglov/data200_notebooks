{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spam Detection Filter\n",
    "\n",
    "Let us illustrate a few concepts from before on a case study -- building a spam detection filter. The data for this notebook is from https://medium.com/analytics-vidhya/building-a-spam-filter-from-scratch-using-machine-learning-fc58b178ea56.\n",
    "\n",
    "## Read Data\n",
    "\n",
    "The emails are currently organized in four directories (see data/email): nonspam-train, nonspam-test, spam-train, and spam-test, with one file per email. The data looks preprocessed, i.e. lower-cased, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mnonspam-test\u001b[0m/\r\n",
      "\u001b[01;34mnonspam-train\u001b[0m/\r\n",
      "\u001b[01;34mspam-test\u001b[0m/\r\n",
      "\u001b[01;34mspam-train\u001b[0m/\r\n"
     ]
    }
   ],
   "source": [
    "%ls data/email | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Legit email example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "posting hi m work phonetics project modern irish m hard source anyone recommend book article english specifically interest palatal slender consonant work helpful too thank laurel sutton sutton garnet berkeley edu "
     ]
    }
   ],
   "source": [
    "%cat data/email/nonspam-train/3-380msg4.txt | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spam email:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "great parttime summer job display box credit application need place small owneroperate store area here introduce yourself store owner manager our effective script tell little display box save customer hundred dollar draw card business every app send spot counter place box nothing need need name address company send commission check compensaation every box place become representative earn commission each application store course much profitable plan pay month small effort call code hours receive detail removed our mailing list type b hotmail com area remove subject area e mail send "
     ]
    }
   ],
   "source": [
    "%cat data/email/spam-train/spmsga1.txt | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We arrange the data into two Pandas dataframes: df_train and df_test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./data/email/spam-train/spmsga95.txt',\n",
       " './data/email/spam-train/spmsgc4.txt',\n",
       " './data/email/spam-train/spmsgc108.txt',\n",
       " './data/email/spam-train/spmsga32.txt',\n",
       " './data/email/spam-train/spmsgc50.txt']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_dir = \"./data/email\"\n",
    "train_spam, train_legit = \"./data/email/spam-train/*\", \"./data/email/nonspam-train/*\"\n",
    "test_spam,test_legit = \"./data/email/spam-test/*\", \"./data/email/nonspam-test/*\"\n",
    "file_paths = glob.glob('./data/email/spam-train/*')\n",
    "file_paths[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((700, 2), (260, 2))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_emails(dir_):\n",
    "     return [' '.join(open(file_path, \"r\").readlines()).strip() for file_path in glob.glob(dir_)]\n",
    "\n",
    "def read_df(spam_dir, legit_dir):\n",
    "    # spam\n",
    "    df_spam = pd.DataFrame({'email':read_emails(spam_dir)})\n",
    "    df_spam['spam'] = 1\n",
    "    # legit\n",
    "    df_legit = pd.DataFrame({'email':read_emails(legit_dir)})\n",
    "    df_legit['spam'] = 0\n",
    "    return pd.concat([df_spam,df_legit])\n",
    "\n",
    "df_train = read_df(train_spam, train_legit)\n",
    "df_test = read_df(test_spam, test_legit)\n",
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is what the data look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>email</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>service update due significant rapid policy ch...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>home base travel biz free cruise k st mo incom...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ask join kiddin list owner kiddin invite join ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pardon intrusion want read follow pardon intru...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>international driver s license need driver s l...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               email  spam\n",
       "0  service update due significant rapid policy ch...     1\n",
       "1  home base travel biz free cruise k st mo incom...     1\n",
       "2  ask join kiddin list owner kiddin invite join ...     1\n",
       "3  pardon intrusion want read follow pardon intru...     1\n",
       "4  international driver s license need driver s l...     1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>email</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>thief proof car thief proof car peripheral con...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>eureka hey check everythig site free s actuall...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hello university degree programs increase pers...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>change life money excuses both dares nothing n...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hot free xxx software hetero http csend straig...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               email  spam\n",
       "0  thief proof car thief proof car peripheral con...     1\n",
       "1  eureka hey check everythig site free s actuall...     1\n",
       "2  hello university degree programs increase pers...     1\n",
       "3  change life money excuses both dares nothing n...     1\n",
       "4  hot free xxx software hetero http csend straig...     1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# May be save it for future use?\n",
    "#df_train.to_csv('./data/email/train.csv')\n",
    "#df_test.to_csv('./data/email/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TfidfVectorizer\n",
    "\n",
    "We are going to use a bag-of-words model to translate each email into a feature vector. TfidfVectorizer (term-frequency * inverse document frequency) will do the translation. Another option is using CountVectorizer that does not consider the overall document frequency of each word.\n",
    "\n",
    "See also the commented out parameters when creating tf:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = TfidfVectorizer(\n",
    "    #ngram_range = (1,2) # how many words per each term?\n",
    "    #,stop_words = 'english' # do we want to use the stop words?\n",
    "    #,max_features = 10000 # what is the max vocabulary size?\n",
    "    #,max_df = 1.0 # maximum document frequency\n",
    "    #,min_df = 1.0 # minimum document frequency\n",
    ")\n",
    "X_train = tf.fit_transform(df_train['email'])\n",
    "y_train = df_train['spam']\n",
    "X_test = tf.transform(df_test['email'])\n",
    "y_test = df_test['spam']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((700, 19073), (700,), (260, 19073), (260,))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principal Component Analysis\n",
    "\n",
    "The feature vector currently has X_train.shape[1] features that are not necessarily orthogonal to each other. To reduce the number of features, let us apply the Principal Component Analysis (PCA):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = PCA() # use all defaults\n",
    "\n",
    "p.fit(\n",
    "    X_train.todense() # X_train is a sparse array, so we convert it to dense array first\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many features (components) are needed to explain 95% of the variance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "598"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_comps = np.argmax(np.cumsum(p.explained_variance_) > 0.95)\n",
    "n_comps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-run the PCA with that many components. You can re-do PCA with more or fewer components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((700, 598), (260, 598))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = PCA(n_components = n_comps)\n",
    "X_train_pca = p.fit_transform(X_train.todense())\n",
    "X_test_pca = p.transform(X_test.todense())\n",
    "X_train_pca.shape,X_test_pca.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "We try a few models on our data:\n",
    "* Logistic Regression\n",
    "* An artificial neural network\n",
    "\n",
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(\n",
    "    random_state = 1\n",
    "    , solver = 'lbfgs'\n",
    ")\n",
    "lr.fit(X_train_pca, y_train)\n",
    "y_pred = lr.predict(X_test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       legit       0.97      0.99      0.98       130\n",
      "        spam       0.99      0.97      0.98       130\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       260\n",
      "   macro avg       0.98      0.98      0.98       260\n",
      "weighted avg       0.98      0.98      0.98       260\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred, target_names = ['legit','spam']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model performance is really good. The lowest scores are the precision on the legit emails and recall on spam ones. It means that the logistic regression occasionally fails to filter out spam emails. The good news is that 99% of the legit emails are recognized as legit. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Artificial Neural Network\n",
    "\n",
    "At this time, let us try an artificial neural network and see if we can improve the scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = MLPClassifier(hidden_layer_sizes = [100,100,10]\n",
    "                   ,learning_rate_init = 0.0002\n",
    "                   ,max_iter = 1000\n",
    "                   ,verbose = 1, random_state = 2)\n",
    "nn.fit(X_train_pca, y_train)\n",
    "y_pred = nn.predict(X_test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       legit       0.99      0.99      0.99       130\n",
      "        spam       0.99      0.99      0.99       130\n",
      "\n",
      "   micro avg       0.99      0.99      0.99       260\n",
      "   macro avg       0.99      0.99      0.99       260\n",
      "weighted avg       0.99      0.99      0.99       260\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred, target_names = ['legit','spam']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying out the spam filter\n",
    "\n",
    "Let us put all the steps into a pipeline:\n",
    "* TfidFVectorizer to convert the text to word counts;\n",
    "* Transform the sparse matrix to dense;\n",
    "* Apply principal component analysis;\n",
    "* Run artificial neural network to predict if the email is spam;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline([('tfidfvectorizer',tf)\n",
    "                 ,('todense',FunctionTransformer(lambda x: x.todense(), accept_sparse=True, validate = False))\n",
    "                 ,('pca',p)\n",
    "                 ,('ann',nn)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method returns two numbers which can be thought of as 'probabilities' that the email is legit (1st) vs. spam (2nd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.02945142,  0.97054858]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba(['Hello'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also call it at runtime and see its work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "227ab9c651ff431bb2bb79c86f3ab310",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Text(value='Hi there!', description='x'), Output()), _dom_classes=('widget-interact',))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.<lambda>>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interact(lambda x:print(\"Spam probability: %.2f%%\"%(model.predict_proba([x])[0][1]*100.0))\n",
    "         , x='Hi there!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
